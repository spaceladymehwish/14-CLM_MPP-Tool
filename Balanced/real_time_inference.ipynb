{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **real time inference**"
      ],
      "metadata": {
        "id": "gQCMf3Bx_h-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit-pypi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRXsLa2x3qg9",
        "outputId": "ad61db0e-a4c1-4cf9-ec3d-ee3c2df6fd47"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rdkit-pypi in /usr/local/lib/python3.11/dist-packages (2022.9.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit-pypi) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit-pypi) (11.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y numpy\n",
        "!pip install numpy==1.24"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "g507fhNQ4SGG",
        "outputId": "9393d82d-37a8-44cb-e592-5497131a8fd4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "Collecting numpy==1.24\n",
            "  Downloading numpy-1.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Downloading numpy-1.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m117.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.0 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.0 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.0 which is incompatible.\n",
            "pymc 5.23.0 requires numpy>=1.25.0, but you have numpy 1.24.0 which is incompatible.\n",
            "blosc2 3.3.4 requires numpy>=1.26, but you have numpy 1.24.0 which is incompatible.\n",
            "xarray-einstats 0.9.0 requires numpy>=1.25, but you have numpy 1.24.0 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.24.0 which is incompatible.\n",
            "seaborn 0.13.2 requires numpy!=1.24.0,>=1.20, but you have numpy 1.24.0 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.24.0 which is incompatible.\n",
            "albumentations 2.0.8 requires numpy>=1.24.4, but you have numpy 1.24.0 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.0 which is incompatible.\n",
            "albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.24.0 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "fce5411015144547ad9c27831e948cfd"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y pandas\n",
        "!pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Sl5UdpS4VHD",
        "outputId": "82cd2eb0-d001-42cf-fccd-cb1c5adf0cc5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: pandas 2.2.2\n",
            "Uninstalling pandas-2.2.2:\n",
            "  Successfully uninstalled pandas-2.2.2\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.24.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading pandas-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m111.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pandas\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.0 which is incompatible.\n",
            "pymc 5.23.0 requires numpy>=1.25.0, but you have numpy 1.24.0 which is incompatible.\n",
            "seaborn 0.13.2 requires numpy!=1.24.0,>=1.20, but you have numpy 1.24.0 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.0 which is incompatible.\n",
            "dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-2.3.0\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the model class exactly as before\n",
        "class ImprovedMolecularNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(ImprovedMolecularNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 512)\n",
        "        self.bn1 = nn.BatchNorm1d(512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.bn2 = nn.BatchNorm1d(256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.bn3 = nn.BatchNorm1d(128)\n",
        "        self.fc4 = nn.Linear(128, 64)\n",
        "        self.bn4 = nn.BatchNorm1d(64)\n",
        "        self.fc5 = nn.Linear(64, 1)\n",
        "\n",
        "        self.leaky_relu = nn.LeakyReLU(0.1)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.leaky_relu(self.bn1(self.fc1(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.leaky_relu(self.bn2(self.fc2(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.leaky_relu(self.bn3(self.fc3(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.leaky_relu(self.bn4(self.fc4(x)))\n",
        "        x = self.sigmoid(self.fc5(x))\n",
        "        return x\n",
        "\n",
        "# Set input dimension (update if needed)\n",
        "input_dim = 140  # or whatever your feature size is\n",
        "# The model class must be defined before loading the state_dict\n",
        "model = ImprovedMolecularNN(input_dim) # Instantiate the model with the correct input dimension\n",
        "# Load the model state dictionary, mapping parameters to the instantiated model\n",
        "model = torch.load(\"1-2D rdki best nn_model.pth\", map_location=torch.device('cpu'), weights_only=False)\n",
        "model.eval()"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1vvDBHQ44ca",
        "outputId": "b93ba144-4b4f-47fb-d59a-0ad77730199a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ImprovedMolecularNN(\n",
              "  (fc1): Linear(in_features=140, out_features=512, bias=True)\n",
              "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc4): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (bn4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc5): Linear(in_features=64, out_features=1, bias=True)\n",
              "  (leaky_relu): LeakyReLU(negative_slope=0.1)\n",
              "  (dropout): Dropout(p=0.4, inplace=False)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "source": [
        "from rdkit import Chem\n",
        "from rdkit.ML.Descriptors import MoleculeDescriptors\n",
        "from rdkit.Chem import Descriptors\n",
        "import numpy as np\n",
        "\n",
        "# Define the *exact* list of 140 descriptors used during training\n",
        "# Replace this list with the actual 140 descriptor names\n",
        "descriptor_names = [\n",
        "    'MaxEStateIndex', 'MinEStateIndex', 'MinAbsEStateIndex', 'qed', 'MolWt',\n",
        "    'NumRadicalElectrons', 'MaxPartialCharge', 'MinPartialCharge', 'FpDensityMorgan1',\n",
        "    'BCUT2D_MWHI', 'BCUT2D_MWLOW', 'BCUT2D_CHGHI', 'BCUT2D_CHGLO', 'BCUT2D_MRHI',\n",
        "    'BCUT2D_MRLOW', 'BalabanJ', 'HallKierAlpha', 'Kappa3',\n",
        "    'PEOE_VSA1', 'PEOE_VSA10', 'PEOE_VSA11', 'PEOE_VSA12', 'PEOE_VSA13', 'PEOE_VSA14',\n",
        "    'PEOE_VSA2', 'PEOE_VSA3', 'PEOE_VSA4', 'PEOE_VSA5', 'PEOE_VSA6', 'PEOE_VSA7',\n",
        "    'PEOE_VSA8', 'PEOE_VSA9',\n",
        "    'SMR_VSA10', 'SMR_VSA2', 'SMR_VSA3', 'SMR_VSA4', 'SMR_VSA6', 'SMR_VSA7',\n",
        "    'SMR_VSA8', 'SMR_VSA9',\n",
        "    'SlogP_VSA1', 'SlogP_VSA10', 'SlogP_VSA12', 'SlogP_VSA3', 'SlogP_VSA4',\n",
        "    'SlogP_VSA7', 'SlogP_VSA8', 'SlogP_VSA9',\n",
        "    'EState_VSA10', 'EState_VSA11', 'EState_VSA2', 'EState_VSA3', 'EState_VSA4',\n",
        "    'EState_VSA5', 'EState_VSA6', 'EState_VSA7', 'EState_VSA8',\n",
        "    'VSA_EState10', 'VSA_EState3', 'VSA_EState4', 'VSA_EState5', 'VSA_EState9',\n",
        "    'FractionCSP3', 'NumAliphaticCarbocycles', 'NumAliphaticHeterocycles',\n",
        "    'NumAliphaticRings', 'NumAromaticHeterocycles', 'MolLogP',\n",
        "    'fr_Al_COO', 'fr_Al_OH', 'fr_Al_OH_noTert', 'fr_ArN', 'fr_Ar_COO', 'fr_Ar_NH',\n",
        "    'fr_Ar_OH', 'fr_C_S', 'fr_HOCCN', 'fr_Imine', 'fr_NH0', 'fr_NH1', 'fr_NH2',\n",
        "    'fr_N_O', 'fr_Ndealkylation1', 'fr_Ndealkylation2', 'fr_SH', 'fr_aldehyde',\n",
        "    'fr_alkyl_carbamate', 'fr_alkyl_halide', 'fr_allylic_oxid', 'fr_amidine',\n",
        "    'fr_aniline', 'fr_aryl_methyl', 'fr_azide', 'fr_azo', 'fr_barbitur',\n",
        "    'fr_benzodiazepine', 'fr_bicyclic', 'fr_diazo', 'fr_dihydropyridine',\n",
        "    'fr_epoxide', 'fr_ester', 'fr_ether', 'fr_furan', 'fr_guanido', 'fr_halogen',\n",
        "    'fr_hdrzine', 'fr_hdrzone', 'fr_imidazole', 'fr_imide', 'fr_isocyan',\n",
        "    'fr_isothiocyan', 'fr_ketone', 'fr_lactam', 'fr_lactone', 'fr_methoxy',\n",
        "    'fr_morpholine', 'fr_nitrile', 'fr_nitro', 'fr_nitro_arom_nonortho',\n",
        "    'fr_nitroso', 'fr_oxazole', 'fr_oxime', 'fr_para_hydroxylation',\n",
        "    'fr_phos_acid', 'fr_piperdine', 'fr_piperzine', 'fr_priamide', 'fr_prisulfonamd',\n",
        "    'fr_pyridine', 'fr_quatN', 'fr_sulfide', 'fr_sulfonamd', 'fr_sulfone',\n",
        "    'fr_term_acetylene', 'fr_tetrazole', 'fr_thiazole', 'fr_thiocyan',\n",
        "    'fr_thiophene', 'fr_unbrch_alkane', 'fr_urea'\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "# Ensure the number of descriptors matches the model's input dimension\n",
        "assert len(descriptor_names) == input_dim, f\"Mismatch in descriptor count. Expected {input_dim}, got {len(descriptor_names)}\"\n",
        "\n",
        "descriptor_calculator = MoleculeDescriptors.MolecularDescriptorCalculator(descriptor_names)\n",
        "\n",
        "def smiles_to_descriptors(smiles: str) -> np.ndarray:\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        raise ValueError(f\"Invalid SMILES: {smiles}\")\n",
        "\n",
        "    descriptors = descriptor_calculator.CalcDescriptors(mol)\n",
        "    return np.array(descriptors, dtype=np.float32)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "JF83eCUJ5GTD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "source": [
        "import numpy as np\n",
        "\n",
        "def predict(input_features):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        input_tensor = torch.tensor(input_features, dtype=torch.float32)\n",
        "\n",
        "        # If input is 1D (single sample), add batch dimension\n",
        "        if input_tensor.ndim == 1:\n",
        "            input_tensor = input_tensor.unsqueeze(0)\n",
        "\n",
        "        output = model(input_tensor)\n",
        "        prediction = output.item()\n",
        "        return prediction"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "iszVvQHA5JJA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "source": [
        "def predict_from_smiles(smiles: str) -> float:\n",
        "    input_features = smiles_to_descriptors(smiles)\n",
        "    return predict(input_features)  # predict() is the function from earlier"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "u7GoHkCz5Jp5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "source": [
        "smiles = \"CC(=O)OC1=CC=CC=C1C(=O)O\"  # Aspirin\n",
        "score = predict_from_smiles(smiles)\n",
        "label = 1 if score > 0.5 else 0\n",
        "print(\"Predicted probability of activity:\", score)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eU94IwZ35Kbc",
        "outputId": "b76a2085-4426-429f-a7a4-f2bdeb317af5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted probability of activity: 0.9997808337211609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smiles = \"CC1([C@@H](N2[C@H](S1)[C@@H](C2=O)NC(=O)Cc3ccccc3)C(=O)O)C\"  # Aspirin\n",
        "score = predict_from_smiles(smiles)\n",
        "label = 1 if score > 0.5 else 0\n",
        "print(\"Predicted class label:\", label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dv4yPIi8qBw",
        "outputId": "debef38d-28c4-4a24-eb3d-008f4a5eeef1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class label: 1\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# Define the list of SMILES strings you want to process\n",
        "smiles_list = [\n",
        "    \"CCO\",  # Ethanol\n",
        "    \"C\",   # Methane\n",
        "    \"CC(=O)N\", # Acetamide\n",
        "    \"C1=CC=CC=C1\" # Benzene\n",
        "    # Add more SMILES strings to this list as needed\n",
        "]\n",
        "\n",
        "for s in smiles_list:\n",
        "    score = predict_from_smiles(s)\n",
        "    label = 1 if score > 0.5 else 0\n",
        "    print(f\"SMILES: {s} | Score: {score:.4f} | Predicted label: {label}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kuzZekh9wK3",
        "outputId": "f18ca91f-cac9-4c24-c0f1-4dc45db6d93e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SMILES: CCO | Score: 0.9974 | Predicted label: 1\n",
            "SMILES: C | Score: 0.9796 | Predicted label: 1\n",
            "SMILES: CC(=O)N | Score: 0.9952 | Predicted label: 1\n",
            "SMILES: C1=CC=CC=C1 | Score: 0.9997 | Predicted label: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **balancing**"
      ],
      "metadata": {
        "id": "FH8nV02k_d4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: train and test svm rbf on this data RDkit-2D_scaled_data\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Load your data\n",
        "RDkit_2D_scaled_data = pd.read_csv('RDkit-2D_scaled_data.csv')\n",
        "\n",
        "# Replace 'target_column' with the actual name of your target variable column\n",
        "X = RDkit_2D_scaled_data.drop('values', axis=1)\n",
        "y = RDkit_2D_scaled_data['values']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Initialize the SVM classifier with RBF kernel\n",
        "svm_rbf = SVC(kernel='rbf', random_state=42, class_weight='balanced')\n",
        "\n",
        "# Train the model\n",
        "svm_rbf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = svm_rbf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"SVM RBF Classifier Performance:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2z-xkqL_VO5",
        "outputId": "cf522a23-4f5c-4a6d-fe78-9697757a86e5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM RBF Classifier Performance:\n",
            "Accuracy: 0.622588424437299\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.84      0.69      1244\n",
            "           1       0.71      0.41      0.52      1244\n",
            "\n",
            "    accuracy                           0.62      2488\n",
            "   macro avg       0.65      0.62      0.60      2488\n",
            "weighted avg       0.65      0.62      0.60      2488\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: make real time testing using this model\n",
        "\n",
        "def real_time_testing(smiles_list):\n",
        "    \"\"\"\n",
        "    Performs real-time inference on a list of SMILES strings using the loaded model.\n",
        "\n",
        "    Args:\n",
        "        smiles_list (list): A list of SMILES strings to predict on.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Real-Time Testing ---\")\n",
        "    for smiles in smiles_list:\n",
        "        try:\n",
        "            score = predict_from_smiles(smiles)\n",
        "            label = 1 if score > 0.5 else 0\n",
        "            print(f\"SMILES: {smiles} | Score: {score:.4f} | Predicted label: {label}\")\n",
        "        except ValueError as e:\n",
        "            print(f\"Error processing SMILES '{smiles}': {e}\")\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred for SMILES '{smiles}': {e}\")\n",
        "\n",
        "# Example usage of the real_time_testing function\n",
        "test_smiles = [\n",
        "    \"CCC\",         # Propane\n",
        "    \"O=C(C)Oc1ccccc1C(=O)O\", # Another Aspirin representation\n",
        "    \"invalid_smiles\", # An invalid SMILES string to test error handling\n",
        "    \"C1=CC=NC=C1\" # Pyridine\n",
        "]\n",
        "\n",
        "real_time_testing(test_smiles)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wl-fiCvjAekA",
        "outputId": "bd0216fa-d817-4260-b87c-d2747ca6dc45"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Real-Time Testing ---\n",
            "SMILES: CCC | Score: 0.9773 | Predicted label: 1\n",
            "SMILES: O=C(C)Oc1ccccc1C(=O)O | Score: 0.9998 | Predicted label: 1\n",
            "Error processing SMILES 'invalid_smiles': Invalid SMILES: invalid_smiles\n",
            "SMILES: C1=CC=NC=C1 | Score: 0.9998 | Predicted label: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[14:05:15] SMILES Parse Error: syntax error while parsing: invalid_smiles\n",
            "[14:05:15] SMILES Parse Error: Failed parsing SMILES 'invalid_smiles' for input: 'invalid_smiles'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_smiles = [\"CCO\", \"C\", \"CC(=O)N\", \"C1=CC=CC=C1\"]\n",
        "real_time_testing(test_smiles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERck8nggAr72",
        "outputId": "0927ea8a-4042-4a5b-ce78-326b56eef6fe"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Real-Time Testing ---\n",
            "SMILES: CCO | Score: 0.9974 | Predicted label: 1\n",
            "SMILES: C | Score: 0.9796 | Predicted label: 1\n",
            "SMILES: CC(=O)N | Score: 0.9952 | Predicted label: 1\n",
            "SMILES: C1=CC=CC=C1 | Score: 0.9997 | Predicted label: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: train and test on random forest\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize the Random Forest classifier\n",
        "# You can adjust n_estimators (number of trees), max_depth, etc.\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
        "\n",
        "# Train the Random Forest model\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_rf = rf_clf.predict(X_test)\n",
        "\n",
        "# Evaluate the Random Forest model\n",
        "print(\"\\nRandom Forest Classifier Performance:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jjd8YenTEefU",
        "outputId": "0bf2723c-2ae5-4fb6-8b2a-6b1bc7dfff87"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random Forest Classifier Performance:\n",
            "Accuracy: 0.5711414790996785\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.66      0.61      1244\n",
            "           1       0.59      0.48      0.53      1244\n",
            "\n",
            "    accuracy                           0.57      2488\n",
            "   macro avg       0.57      0.57      0.57      2488\n",
            "weighted avg       0.57      0.57      0.57      2488\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: train and test the model using random forest grid search cv\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid to search\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "# cv=5 means 5-fold cross-validation\n",
        "# scoring='accuracy' can be changed to 'f1', 'roc_auc', etc. depending on the metric you want to optimize\n",
        "grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
        "                           param_grid=param_grid,\n",
        "                           cv=5,\n",
        "                           scoring='accuracy',\n",
        "                           n_jobs=-1, # Use all available cores\n",
        "                           verbose=1) # Print progress\n",
        "\n",
        "# Perform the grid search on the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters found\n",
        "print(\"\\nBest parameters found by Grid Search:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "# Get the best estimator (the model trained with the best parameters)\n",
        "best_rf_clf = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions on the test set using the best model\n",
        "y_pred_best_rf = best_rf_clf.predict(X_test)\n",
        "\n",
        "# Evaluate the best model\n",
        "print(\"\\nRandom Forest Classifier Performance after Grid Search:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_best_rf))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_best_rf))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYkRG2dKEpem",
        "outputId": "ba785408-93a9-447d-af89-066e1880c755"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
            "\n",
            "Best parameters found by Grid Search:\n",
            "{'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}\n",
            "\n",
            "Random Forest Classifier Performance after Grid Search:\n",
            "Accuracy: 0.6117363344051447\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.86      0.69      1244\n",
            "           1       0.72      0.36      0.48      1244\n",
            "\n",
            "    accuracy                           0.61      2488\n",
            "   macro avg       0.65      0.61      0.59      2488\n",
            "weighted avg       0.65      0.61      0.59      2488\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: real time testing on smiles\n",
        "\n",
        "# You can reuse the existing real_time_testing function.\n",
        "# It is already defined and demonstrated in the preceding code.\n",
        "# Just call it with the list of SMILES you want to test in real-time.\n",
        "\n",
        "# Example of calling the real_time_testing function with a new list of SMILES\n",
        "print(\"\\n--- Performing real-time testing on new SMILES list ---\")\n",
        "new_smiles_for_testing = [\n",
        "    \"C1=CC=C(C=C1)N\", # Aniline\n",
        "    \"CC(C)(C)O\",      # tert-Butanol\n",
        "    \"O=C1CCCCC1\",    # Cyclohexanone\n",
        "    \"CCOc1ccccc1\"    # Phenetole\n",
        "]\n",
        "\n",
        "real_time_testing(new_smiles_for_testing)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLwNJzNVU00X",
        "outputId": "67cb3064-1e71-415b-e4b5-ffb640ad2612"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Performing real-time testing on new SMILES list ---\n",
            "\n",
            "--- Real-Time Testing ---\n",
            "SMILES: C1=CC=C(C=C1)N | Score: 0.9999 | Predicted label: 1\n",
            "SMILES: CC(C)(C)O | Score: 1.0000 | Predicted label: 1\n",
            "SMILES: O=C1CCCCC1 | Score: 0.9967 | Predicted label: 1\n",
            "SMILES: CCOc1ccccc1 | Score: 0.9999 | Predicted label: 1\n"
          ]
        }
      ]
    }
  ]
}